{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clnd_data=pd.read_csv(\"cleaned_tweets_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vctrr= TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "tfidf_features = tfidf_vctrr.fit_transform(clnd_data['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tfidf_features\n",
    "Y=clnd_data[\"airline_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "rand_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rand_forest.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1581  175   64]\n",
      " [ 280  265   60]\n",
      " [ 120   64  262]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83      1820\n",
      "     neutral       0.53      0.44      0.48       605\n",
      "    positive       0.68      0.59      0.63       446\n",
      "\n",
      "    accuracy                           0.73      2871\n",
      "   macro avg       0.67      0.63      0.65      2871\n",
      "weighted avg       0.72      0.73      0.73      2871\n",
      "\n",
      "0.7342389411354928\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 47.0min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 325.9min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 647.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_sc...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_opt = best_random.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1657  103   60]\n",
      " [ 339  210   56]\n",
      " [ 155   36  255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.91      0.83      1820\n",
      "     neutral       0.60      0.35      0.44       605\n",
      "    positive       0.69      0.57      0.62       446\n",
      "\n",
      "    accuracy                           0.74      2871\n",
      "   macro avg       0.69      0.61      0.63      2871\n",
      "weighted avg       0.72      0.74      0.72      2871\n",
      "\n",
      "73.91152908394287\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(confusion_matrix(y_test,y_pred_opt))\n",
    "print(classification_report(y_test,y_pred_opt))\n",
    "print(accuracy_score(y_test, y_pred_opt)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before hyperparamter tuning the accuracy was 73.4 \n",
    "#after hyperparamter tuning the accuracy increased .5% (73.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'negative', ..., 'negative', 'negative',\n",
       "       'negative'], dtype=object)"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=clnd_data[\"airline_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1         neutral\n",
       "2        negative\n",
       "3        negative\n",
       "4        negative\n",
       "5        positive\n",
       "6         neutral\n",
       "7        positive\n",
       "8         neutral\n",
       "9        positive\n",
       "10       positive\n",
       "11       positive\n",
       "12       positive\n",
       "13       negative\n",
       "14       positive\n",
       "15       negative\n",
       "16       positive\n",
       "17       positive\n",
       "18       negative\n",
       "19       positive\n",
       "20       positive\n",
       "21        neutral\n",
       "22       negative\n",
       "23       negative\n",
       "24       negative\n",
       "25        neutral\n",
       "26       negative\n",
       "27        neutral\n",
       "28       negative\n",
       "29        neutral\n",
       "           ...   \n",
       "14323    negative\n",
       "14324     neutral\n",
       "14325    negative\n",
       "14326    negative\n",
       "14327    negative\n",
       "14328    negative\n",
       "14329    negative\n",
       "14330    positive\n",
       "14331    negative\n",
       "14332    positive\n",
       "14333    negative\n",
       "14334    negative\n",
       "14335    negative\n",
       "14336    positive\n",
       "14337    negative\n",
       "14338    positive\n",
       "14339    negative\n",
       "14340    negative\n",
       "14341    positive\n",
       "14342    negative\n",
       "14343    positive\n",
       "14344    negative\n",
       "14345     neutral\n",
       "14346    negative\n",
       "14347    negative\n",
       "14348    positive\n",
       "14349    negative\n",
       "14350     neutral\n",
       "14351    negative\n",
       "14352     neutral\n",
       "Name: airline_sentiment, Length: 14353, dtype: object"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_labels(data_,col_name,file_name):\n",
    "    \"\"\"this function takes the DataFrame, column name and the file name\n",
    "    then encodes the catigorical variable using LabelEncoder & OneHotEncoder \n",
    "    and save the new data frame to a csv file \n",
    "    then returns the encoder instance, the Dataframe with the encoded variables with two additional columns Male-Female \n",
    "    and another dataframe with encoded gender column \"\"\"\n",
    "    #airline_sentiment\n",
    "    data_lbl=data_.copy()\n",
    "    data_pure=data_.copy()\n",
    "\n",
    "    sent_encoding=LabelEncoder()\n",
    "    sent_labels=sent_encoding.fit_transform(data_pure[col_name])\n",
    "    \n",
    "    encoding_objects={}\n",
    "    \n",
    "\n",
    "    encoding_objects[col_name]=LabelEncoder()\n",
    "    data_pure[col_name]=encoding_objects[col_name].fit_transform(data_pure[col_name])\n",
    "            \n",
    "    #print(encoding_objects)\n",
    "    \n",
    "    sent_lbl_enc=LabelEncoder()\n",
    "    sent_1_hot_enc=OneHotEncoder()\n",
    "    \n",
    "    data_lbl[col_name]=sent_lbl_enc.fit_transform(data_lbl[col_name])\n",
    "    sent_values=sent_1_hot_enc.fit_transform(data_lbl[col_name].values.reshape(-1,1)).toarray()\n",
    "    \n",
    "    #print(gender_values)\n",
    "    #print(data_lbl[\"Gender\"])\n",
    "    \n",
    "    cols_sent=sent_lbl_enc.inverse_transform(data_lbl[col_name].unique())\n",
    "    for i in range(len(cols_sent)):\n",
    "        data_lbl[cols_sent[i]]=sent_values[:,i]\n",
    "    #print(cols_gender)\n",
    "    \n",
    "    data_lbl.to_csv(file_name,index=False)\n",
    "    data_pure.to_csv(\"encoded_labeled_df.csv\",index=False)\n",
    "    return sent_lbl_enc, data_lbl, data_pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"Sent_encoded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programs\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LabelEncoder(),\n",
       "        airline_sentiment                                               text  \\\n",
       " 0                      2      'added', 'commercials', 'experience', 'tacky'   \n",
       " 1                      1                                 'today', 'another'   \n",
       " 2                      0  'really', 'aggressive', 'blast', 'obnoxious', ...   \n",
       " 3                      0                                  'really', 'thing'   \n",
       " 4                      0  'seriously', 'would', 'flight', 'seats', 'play...   \n",
       " 5                      2                                  'nearly', 'every'   \n",
       " 6                      1  'really', 'missed', 'prime', 'opportunity', 'w...   \n",
       " 7                      2                      'amazing', 'arrived', 'early'   \n",
       " 8                      1  'suicide', 'second', 'leading', 'cause', 'deat...   \n",
       " 9                      2  'pretty', 'graphics', 'better', 'minimal', 'ic...   \n",
       " 10                     2                     'great', 'already', 'thinking'   \n",
       " 11                     2  'flying', 'fabulous', 'seductive', 'skies', 's...   \n",
       " 12                     2                                           'thanks'   \n",
       " 13                     0                                'schedule', 'still'   \n",
       " 14                     2  'excited', 'first', 'cross', 'country', 'fligh...   \n",
       " 15                     0            'fully', 'large', 'gentleman', 'either'   \n",
       " 16                     2                                           'flying'   \n",
       " 17                     2          'would', 'amazingly', 'awesome', 'please'   \n",
       " 18                     0  'first', 'fares', 'three', 'times', 'carriers'...   \n",
       " 19                     2                            'graphic', 'ut5grrwaaa'   \n",
       " 20                     2                   'hipster', 'innovation', 'brand'   \n",
       " 21                     1                 'making', 'permanently', 'anytime'   \n",
       " 22                     0  'messed', 'seating', 'reserved', 'seating', 'f...   \n",
       " 23                     0  'status', 'match', 'program', 'applied', 'thre...   \n",
       " 24                     0  'happened', 'vegan', 'options', 'least', 'anyt...   \n",
       " 25                     1                                'worry', 'together'   \n",
       " 26                     0  'amazing', 'vents', 'vx358', 'noair', 'worstfl...   \n",
       " 27                     1   'middle', 'maneuver', 'sendambien', 'andchexmix'   \n",
       " 28                     0  'birthday', 'elevate', 'cause', 'entered', 'mi...   \n",
       " 29                     1  'hours', 'operation', 'posted', 'online', 'cur...   \n",
       " ...                  ...                                                ...   \n",
       " 14323                  0  'understand', 'weather', 'issue', 'expect', 'p...   \n",
       " 14324                  1                'guarantee', 'retribution', 'share'   \n",
       " 14325                  0  'friend', 'flight', 'cancelled', 'flightlation...   \n",
       " 14326                  0  'feature', 'operator', 'regarding', 'flight', ...   \n",
       " 14327                  0  'tomorrow', 'therefore', 'direct', 'message', ...   \n",
       " 14328                  0  'luggage', 'cancelled', 'flight', 'flight', 't...   \n",
       " 14329                  0  'cancelled', 'flights', 'flight', 'email', 'ea...   \n",
       " 14330                  2                                  'dming', 'thanks'   \n",
       " 14331                  0  'overweight', 'dozen', 'passengers', 'luggage'...   \n",
       " 14332                  2  'company', 'staff', 'amazing', 'uncomfortable'...   \n",
       " 14333                  0                   'protection', 'minute', 'answer'   \n",
       " 14334                  0  'cancelled', 'flighted', 'international', 'fli...   \n",
       " 14335                  0      'place', 'sleep', 'without', 'accommodations'   \n",
       " 14336                  2  'planes', 'maybe', 'amenities', 'function', 'n...   \n",
       " 14337                  0  'chairman', 'emerald', 'today', 'former', 'cus...   \n",
       " 14338                  2  'flight', 'great', 'fantastic', 'cabin', 'land...   \n",
       " 14339                  0  'flight', 'buenos', 'aires', 'delay', 'since',...   \n",
       " 14340                  0  'flight', 'cancelled', 'flightled', 'tomorrow'...   \n",
       " 14341                  2  'thank', 'customer', 'relations', 'review', 'c...   \n",
       " 14342                  0  'change', 'flight', 'phone', 'system', 'keeps'...   \n",
       " 14343                  2                                           'thanks'   \n",
       " 14344                  0  'nothing', 'getting', 'country', 'broken', 'pl...   \n",
       " 14345                  1  'george', 'please', 'follow', 'start', 'refund...   \n",
       " 14346                  0  'flight', 'cancelled', 'flightled', 'leaving',...   \n",
       " 14347                  0                                  'right', 'delays'   \n",
       " 14348                  2          'thank', 'different', 'flight', 'chicago'   \n",
       " 14349                  0  'leaving', 'minutes', 'flight', 'warnings', 'c...   \n",
       " 14350                  1  'please', 'bring', 'american', 'airlines', 'bl...   \n",
       " 14351                  0  'money', 'change', 'flight', 'answer', 'phones...   \n",
       " 14352                  1   'seats', 'flight', 'standby', 'people', 'flight'   \n",
       " \n",
       "        positive  neutral  negative  \n",
       " 0           0.0      0.0       1.0  \n",
       " 1           0.0      1.0       0.0  \n",
       " 2           1.0      0.0       0.0  \n",
       " 3           1.0      0.0       0.0  \n",
       " 4           1.0      0.0       0.0  \n",
       " 5           0.0      0.0       1.0  \n",
       " 6           0.0      1.0       0.0  \n",
       " 7           0.0      0.0       1.0  \n",
       " 8           0.0      1.0       0.0  \n",
       " 9           0.0      0.0       1.0  \n",
       " 10          0.0      0.0       1.0  \n",
       " 11          0.0      0.0       1.0  \n",
       " 12          0.0      0.0       1.0  \n",
       " 13          1.0      0.0       0.0  \n",
       " 14          0.0      0.0       1.0  \n",
       " 15          1.0      0.0       0.0  \n",
       " 16          0.0      0.0       1.0  \n",
       " 17          0.0      0.0       1.0  \n",
       " 18          1.0      0.0       0.0  \n",
       " 19          0.0      0.0       1.0  \n",
       " 20          0.0      0.0       1.0  \n",
       " 21          0.0      1.0       0.0  \n",
       " 22          1.0      0.0       0.0  \n",
       " 23          1.0      0.0       0.0  \n",
       " 24          1.0      0.0       0.0  \n",
       " 25          0.0      1.0       0.0  \n",
       " 26          1.0      0.0       0.0  \n",
       " 27          0.0      1.0       0.0  \n",
       " 28          1.0      0.0       0.0  \n",
       " 29          0.0      1.0       0.0  \n",
       " ...         ...      ...       ...  \n",
       " 14323       1.0      0.0       0.0  \n",
       " 14324       0.0      1.0       0.0  \n",
       " 14325       1.0      0.0       0.0  \n",
       " 14326       1.0      0.0       0.0  \n",
       " 14327       1.0      0.0       0.0  \n",
       " 14328       1.0      0.0       0.0  \n",
       " 14329       1.0      0.0       0.0  \n",
       " 14330       0.0      0.0       1.0  \n",
       " 14331       1.0      0.0       0.0  \n",
       " 14332       0.0      0.0       1.0  \n",
       " 14333       1.0      0.0       0.0  \n",
       " 14334       1.0      0.0       0.0  \n",
       " 14335       1.0      0.0       0.0  \n",
       " 14336       0.0      0.0       1.0  \n",
       " 14337       1.0      0.0       0.0  \n",
       " 14338       0.0      0.0       1.0  \n",
       " 14339       1.0      0.0       0.0  \n",
       " 14340       1.0      0.0       0.0  \n",
       " 14341       0.0      0.0       1.0  \n",
       " 14342       1.0      0.0       0.0  \n",
       " 14343       0.0      0.0       1.0  \n",
       " 14344       1.0      0.0       0.0  \n",
       " 14345       0.0      1.0       0.0  \n",
       " 14346       1.0      0.0       0.0  \n",
       " 14347       1.0      0.0       0.0  \n",
       " 14348       0.0      0.0       1.0  \n",
       " 14349       1.0      0.0       0.0  \n",
       " 14350       0.0      1.0       0.0  \n",
       " 14351       1.0      0.0       0.0  \n",
       " 14352       0.0      1.0       0.0  \n",
       " \n",
       " [14353 rows x 5 columns],\n",
       "        airline_sentiment                                               text\n",
       " 0                      2      'added', 'commercials', 'experience', 'tacky'\n",
       " 1                      1                                 'today', 'another'\n",
       " 2                      0  'really', 'aggressive', 'blast', 'obnoxious', ...\n",
       " 3                      0                                  'really', 'thing'\n",
       " 4                      0  'seriously', 'would', 'flight', 'seats', 'play...\n",
       " 5                      2                                  'nearly', 'every'\n",
       " 6                      1  'really', 'missed', 'prime', 'opportunity', 'w...\n",
       " 7                      2                      'amazing', 'arrived', 'early'\n",
       " 8                      1  'suicide', 'second', 'leading', 'cause', 'deat...\n",
       " 9                      2  'pretty', 'graphics', 'better', 'minimal', 'ic...\n",
       " 10                     2                     'great', 'already', 'thinking'\n",
       " 11                     2  'flying', 'fabulous', 'seductive', 'skies', 's...\n",
       " 12                     2                                           'thanks'\n",
       " 13                     0                                'schedule', 'still'\n",
       " 14                     2  'excited', 'first', 'cross', 'country', 'fligh...\n",
       " 15                     0            'fully', 'large', 'gentleman', 'either'\n",
       " 16                     2                                           'flying'\n",
       " 17                     2          'would', 'amazingly', 'awesome', 'please'\n",
       " 18                     0  'first', 'fares', 'three', 'times', 'carriers'...\n",
       " 19                     2                            'graphic', 'ut5grrwaaa'\n",
       " 20                     2                   'hipster', 'innovation', 'brand'\n",
       " 21                     1                 'making', 'permanently', 'anytime'\n",
       " 22                     0  'messed', 'seating', 'reserved', 'seating', 'f...\n",
       " 23                     0  'status', 'match', 'program', 'applied', 'thre...\n",
       " 24                     0  'happened', 'vegan', 'options', 'least', 'anyt...\n",
       " 25                     1                                'worry', 'together'\n",
       " 26                     0  'amazing', 'vents', 'vx358', 'noair', 'worstfl...\n",
       " 27                     1   'middle', 'maneuver', 'sendambien', 'andchexmix'\n",
       " 28                     0  'birthday', 'elevate', 'cause', 'entered', 'mi...\n",
       " 29                     1  'hours', 'operation', 'posted', 'online', 'cur...\n",
       " ...                  ...                                                ...\n",
       " 14323                  0  'understand', 'weather', 'issue', 'expect', 'p...\n",
       " 14324                  1                'guarantee', 'retribution', 'share'\n",
       " 14325                  0  'friend', 'flight', 'cancelled', 'flightlation...\n",
       " 14326                  0  'feature', 'operator', 'regarding', 'flight', ...\n",
       " 14327                  0  'tomorrow', 'therefore', 'direct', 'message', ...\n",
       " 14328                  0  'luggage', 'cancelled', 'flight', 'flight', 't...\n",
       " 14329                  0  'cancelled', 'flights', 'flight', 'email', 'ea...\n",
       " 14330                  2                                  'dming', 'thanks'\n",
       " 14331                  0  'overweight', 'dozen', 'passengers', 'luggage'...\n",
       " 14332                  2  'company', 'staff', 'amazing', 'uncomfortable'...\n",
       " 14333                  0                   'protection', 'minute', 'answer'\n",
       " 14334                  0  'cancelled', 'flighted', 'international', 'fli...\n",
       " 14335                  0      'place', 'sleep', 'without', 'accommodations'\n",
       " 14336                  2  'planes', 'maybe', 'amenities', 'function', 'n...\n",
       " 14337                  0  'chairman', 'emerald', 'today', 'former', 'cus...\n",
       " 14338                  2  'flight', 'great', 'fantastic', 'cabin', 'land...\n",
       " 14339                  0  'flight', 'buenos', 'aires', 'delay', 'since',...\n",
       " 14340                  0  'flight', 'cancelled', 'flightled', 'tomorrow'...\n",
       " 14341                  2  'thank', 'customer', 'relations', 'review', 'c...\n",
       " 14342                  0  'change', 'flight', 'phone', 'system', 'keeps'...\n",
       " 14343                  2                                           'thanks'\n",
       " 14344                  0  'nothing', 'getting', 'country', 'broken', 'pl...\n",
       " 14345                  1  'george', 'please', 'follow', 'start', 'refund...\n",
       " 14346                  0  'flight', 'cancelled', 'flightled', 'leaving',...\n",
       " 14347                  0                                  'right', 'delays'\n",
       " 14348                  2          'thank', 'different', 'flight', 'chicago'\n",
       " 14349                  0  'leaving', 'minutes', 'flight', 'warnings', 'c...\n",
       " 14350                  1  'please', 'bring', 'american', 'airlines', 'bl...\n",
       " 14351                  0  'money', 'change', 'flight', 'answer', 'phones...\n",
       " 14352                  1   'seats', 'flight', 'standby', 'people', 'flight'\n",
       " \n",
       " [14353 rows x 2 columns])"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_labels(clnd_data,\"airline_sentiment\",file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clnd=pd.read_csv(\"encoded_labeled_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vctrr_2= TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "tfidf_features_2 = tfidf_vctrr_2.fit_transform(new_clnd['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tfidf_features_2\n",
    "Y=new_clnd[\"airline_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(tfidf_features_2, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest_2 = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "rand_forest_2.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = rand_forest_2.predict(X_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1581  175   64]\n",
      " [ 280  265   60]\n",
      " [ 120   64  262]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83      1820\n",
      "           1       0.53      0.44      0.48       605\n",
      "           2       0.68      0.59      0.63       446\n",
      "\n",
      "    accuracy                           0.73      2871\n",
      "   macro avg       0.67      0.63      0.65      2871\n",
      "weighted avg       0.72      0.73      0.73      2871\n",
      "\n",
      "0.7342389411354928\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(confusion_matrix(y_test2,y_pred2))\n",
    "print(classification_report(y_test2,y_pred2))\n",
    "print(accuracy_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
